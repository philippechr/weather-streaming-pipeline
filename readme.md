# üå¶Ô∏è OpenWeatherMap Big Data Streaming Projekt

## üéØ Zielsetzung
Ziel dieses Projekts ist es, eine skalierbare, containerisierte Streaming-Pipeline zur Analyse und Visualisierung von Wetterdaten in Echtzeit aufzubauen. Dabei stehen Robustheit, Erweiterbarkeit (z.‚ÄØB. Anomalieerkennung) sowie Transparenz der Verarbeitung (z.‚ÄØB. durch Zeitstempel & Lag-Analyse) im Fokus.

---

## üóÇÔ∏è Projekt√ºbersicht
Dieses Projekt streamt Wetterdaten von OpenWeatherMap in Echtzeit und verarbeitet sie √ºber eine Event-Streaming-Pipeline. Die Daten werden in einer PostgreSQL-Datenbank gespeichert und mit Grafana visualisiert.

OPENWEATHERMAP-BIGDATA-PROJECT/
‚îú‚îÄ‚îÄ ai_model/
‚îÇ   ‚îú‚îÄ‚îÄ data/                            # Trainingsdaten f√ºr das ML-Modell
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2022_05_01.xlsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2022_05_02.xlsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2022_05_03.xlsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ anomalie.xlsx               # Validierungsset mit Labels
‚îÇ   ‚îú‚îÄ‚îÄ model/                          # Serialisiertes Modell und Scaler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ isolation_forest_model.pkl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl
‚îÇ   ‚îú‚îÄ‚îÄ 01_training.ipynb               # Notebook zum Training (inkl. Export)
‚îÇ   ‚îî‚îÄ‚îÄ 02_predict_anomalies.ipynb      # Notebook zur Validierung & Analyse
‚îú‚îÄ‚îÄ weather_producer.py                 # Producer: API-Aufrufe & Kafka-Push
‚îú‚îÄ‚îÄ weather_beam.py                     # Beam-Consumer mit Preprocessing + ML
‚îú‚îÄ‚îÄ Dockerfile-producer                 # Container-Konfiguration Producer
‚îú‚îÄ‚îÄ Dockerfile-beam                     # Container-Konfiguration Beam + ML
‚îú‚îÄ‚îÄ docker-compose.yml                  # Orchestriert alle Services
‚îú‚îÄ‚îÄ grafana_json_export.json            # Importierbares Dashboard
‚îú‚îÄ‚îÄ .env                                # Lokale Umgebungsvariablen (nicht committet)
‚îú‚îÄ‚îÄ .env.example                        # Beispielhafte .env-Datei
‚îú‚îÄ‚îÄ .gitignore                          # Ignoriert sensible / tempor√§re Dateien
‚îú‚îÄ‚îÄ requirements.txt                    # Python-Abh√§ngigkeiten
‚îî‚îÄ‚îÄ readme.md                           # Projektdokumentation (dieses File)

---

**Architektur:**  
OpenWeatherMap ‚Üí Kafka ‚Üí Apache Beam ‚Üí PostgreSQL ‚Üí Grafana

Alle Komponenten laufen containerisiert √ºber Docker Compose.

---

## üîß Komponenten
| Komponente                        | Aufgabe                                       																			|
|----------------------------------|----------------------------------------------------------------------------------------------------------------------------|
| Kafka & Zookeeper                | Event-Streaming                               																				|
| PostgreSQL                       | Speicherung der Wetterdaten                   																				|
| Grafana                          | Visualisierung                                																				|
| weather_producer.py (Container)  | Holt Wetterdaten, erg√§nzt event_time & received_time und sendet an Kafka       											|
| weather_beam.py (Container)      | Liest von Kafka, erg√§nzt processing_time, filtert, erkennt Anomalien und speichert in PostgreSQL (inkl. Idempotenz)     	|


---

## üìã Gespeicherte Wetterdaten (weather_data)
| Feld             | Einheit / Typ        | Beschreibung                         					|
|------------------|----------------------|---------------------------------------------------------|
| city             | Text                 | Stadtname                            					|
| temperature      | ¬∞C                   | Temperatur                           					|
| humidity         | %                    | Luftfeuchtigkeit                     					|
| pressure         | hPa                  | Luftdruck                            					|
| wind_speed       | km/h                 | Windgeschwindigkeit (berechnet)      					|
| cloud_coverage   | %                    | Bew√∂lkungsgrad                       					|
| weather_main     | Text                 | Wetterkategorie                      					|
| weather_description | Text              | Beschreibung                         					|
| timestamp        | Unix Time (s)        | Zeitpunkt der Messung                					|
| lon / lat        | Koordinaten          | Geografische Lage                    					|
| sys_country      | L√§ndercode           | Nur CH wird gespeichert             					|
| event_time       | Unix Time (s)        | Zeitpunkt der Wettermessung (von API)           		|
| received_time    | Unix Time (s)        | Zeitpunkt, wann die Nachricht im Producer ankam 		|
| processing_time  | Unix Time (s)        | Zeitpunkt, wann der Datensatz in Beam verarbeitet wurde |

---

## üß™ Verarbeitungsschritte in der Apache Beam Pipeline
| Schritt                          | Beam-Typ         | Beschreibung                                                                 											|
|----------------------------------|------------------|-------------------------------------------------------------------------------------------------------------------------|
| Batch laden                      | beam.Create      | L√§dt 10 gesammelte Kafka-Nachrichten in die Pipeline                         											|
| Debug falsche sys_country        | beam.Map         | Gibt Eintr√§ge mit sys_country ‚â† 'CH' zur Kontrolle aus                       											|
| Filtere nur sys_country = CH     | beam.Filter      | L√§sst nur Datens√§tze mit sys_country = 'CH' durch                            											|
| Debug ung√ºltige Werte            | beam.Map         | Gibt Datens√§tze mit fehlenden numerischen Werten (None) aus                  											|
| Filtere nur g√ºltige Werte        | beam.Filter      | Filtert nur Datens√§tze mit vollst√§ndigen Werten (temperature, pressure, etc.)											|
| Windgeschwindigkeit umrechnen    | beam.Map         | Rechnet wind_speed von m/s in **km/h** um (Feldname bleibt gleich)           											|
| Processing-Zeit erg√§nzen		   | beam.Map		  | F√ºgt processing_time als Unix-Zeit hinzu									 											|
| Anomalie erkennen                | beam.Map         | Erkennt Anomalien mit einem ML-Modell (Isolation Forest, via sklearn + pandas)              							|
| In PostgreSQL schreiben          | beam.Map         | Speichert die bereinigten Datens√§tze in der PostgreSQL-Tabelle weather_data (mit Idempotenz (UNIQUE(city, timestamp))) 	|

---

## üß∞ Erweiterungen (Idempotenz, Zeitstempel, Retention, Anomalieerkennung mit Machine Learning)
**Zeitstempel:** Jeder Datensatz enth√§lt drei Zeitpunkte f√ºr vollst√§ndige Nachvollziehbarkeit:
- `event_time`: Zeitpunkt der Messung laut OpenWeatherMap
- `received_time`: Zeitpunkt, wann der Producer die Daten empfangen hat
- `processing_time`: Zeitpunkt, wann Apache Beam den Datensatz verarbeitet hat

**Idempotenz:**  
Duplikate werden vermieden durch `UNIQUE(city, timestamp)` in PostgreSQL + `ON CONFLICT DO NOTHING`.

**Retention:**  
Kafka ist auf eine standardm√§ssige Aufbewahrung von 7 Tagen konfiguriert (`KAFKA_LOG_RETENTION_HOURS = 168`).

**Verz√∂gerungsanalyse (Lag):**  
Durch Vergleich von `processing_time` und `event_time` kann die Systemlatenz berechnet und visualisiert werden.

**Windowing & Triggering**  
In Apache Beam sind Zeitfenster und Trigger entscheidend f√ºr kontinuierliche Streamingverarbeitung. Da in diesem Projekt jedoch feste 10er-Batches verarbeitet werden, erfolgt keine explizite Zeitfensterung (`WindowInto`) oder Trigger-Logik. Die Batchebene √ºbernimmt implizit die Fensterlogik. Daher wird auch kein Watermark oder `AccumulationMode` ben√∂tigt. Die Verarbeitung erfolgt mit dem Modus ‚Äûdiscarding‚Äú durch das explizite √úberschreiben der Datenbank.
‚Üí Vorteil: einfache Kontrolle, deterministisches Verhalten und keine verz√∂gerten Nachlieferungen.

**Anomalieerkennung mit Machine Learningg**  
Der Unterordner ai_model/model/ enth√§lt das produktive Machine-Learning-Modell (isolation_forest_model.pkl) und den zugeh√∂rigen StandardScaler (scaler.pkl) zur Anomalieerkennung. Das Notebook 01_training.ipynb dokumentiert den gesamten Trainingsprozess und erlaubt ein sp√§teres Nachtraining oder Fine-Tuning des Modells mit aktualisierten Daten.

Enthaltene Dateien:
- 2022_05_01.xlsx, 2022_05_02.xlsx, 2022_05_03.xlsx: Rohdaten f√ºr das Training (wurden im Rahmen einer anderen Weiterbildung von Philippe Christen erhoben)
- anomalie.xlsx: validierte Anomalien zur Modell-Evaluierung (stark vereinfacht)
- training.ipynb: Jupyter Notebook zum Training inkl. Feature-Engineering & Modellpersistenz

Ziel: Reproduzierbarkeit und einfache Anpassung bei Modell-Drift oder ver√§nderten Datenmustern.

---

## üîë Konfiguration (.env)
Im Repository befindet sich die Datei `.env.example`.
Bitte kopiere diese und benenne sie in `.env` um.
Anschliessend tr√§gst du deinen pers√∂nlichen API_KEY ein (wird im Rahmen des Projekts per E-Mail bereitgestellt)

---

## ‚ñ∂Ô∏è Starten
Docker Desktop starten

**Build & Start der gesamten Umgebung:**
docker-compose build --no-cache  
docker-compose up -d

**Logs pr√ºfen (optional):**
docker logs openweathermap-bigdata-project-producer-1  
docker logs openweathermap-bigdata-project-beam-1

**Kafka Live-Stream pr√ºfen (optional --> Consumer wird in tempor√§ren Container gestartet):**
docker run -it --network=openweathermap-bigdata-project_default confluentinc/cp-kafka:7.5.0 \
kafka-console-consumer --bootstrap-server kafka:9092 --topic weather_data --from-beginning

**psql Abfrage (optional):**
docker exec -it openweathermap-bigdata-project-postgres-1 psql -U user -d weather
    SELECT * FROM weather_data ORDER BY timestamp DESC LIMIT 100;

**Stoppen:**
docker-compose down --remove-orphans

---

## üîë Zugangsdaten & Ports

| Dienst     | Adresse/Port          | Zugangsdaten   |
|------------|-----------------------|----------------|
| Kafka      | localhost:9092        | -              |
| PostgreSQL | localhost:5432        | user / pass    |
| Grafana    | http://localhost:3000 | admin / admin  |

---

## üìä Grafana einrichten

### Datenquelle hinzuf√ºgen
1. Links: ‚öô Data Sources ‚Üí PostgreSQL ausw√§hlen.
2. Host: postgres:5432
3. Database: weather
4. User: user, Passwort: pass
5. Save & Test ‚Üí sollte ‚ÄûDatabase OK‚Äú anzeigen.

### Panel erstellen ‚Äî Beispiel-Querys

**Temperatur √ºber Zeit:**
SELECT timestamp * 1000 AS "time", temperature  
FROM weather_data  
ORDER BY timestamp ASC;

**Luftfeuchtigkeit √ºber Zeit:**
SELECT timestamp * 1000 AS "time", humidity  
FROM weather_data  
ORDER BY timestamp ASC;

**Lag-Analyse:**
SELECT (processing_time - event_time) AS lag_seconds 
FROM weather_data;

**Anomaly-Analyse:**
SELECT
  to_timestamp(processing_time) AS time,
  city, temperature, wind_speed, pressure, humidity
FROM
  weather_data
WHERE
  anomaly = true
ORDER BY
  processing_time DESC;

**Anomaly-Analyse Heatmap:**
SELECT city, COUNT(*) AS anomaly_count
FROM weather_data
WHERE anomaly = true
GROUP BY city
ORDER BY anomaly_count DESC;


**Importiertes Dashboard**
Das vorkonfigurierte Grafana-Dashboard ist als Datei grafana_json_export.json im Projekt enthalten.
Du kannst es wie folgt importieren:
	1.	√ñffne Grafana unter http://localhost:3000
	2.	Klicke auf ‚Äû+‚Äú ‚Üí ‚ÄûImport‚Äú
	3.	Lade die Datei grafana_json_export.json hoch oder f√ºge den JSON-Inhalt ein
	4.	W√§hle die PostgreSQL-Datenquelle aus und best√§tige mit Import


---

## ‚öôÔ∏è .env-Konfiguration
Alle Parameter werden √ºber die .env-Datei gesteuert:

**Beispielhafte Parameter:**
- `API_KEY` ‚Äì OpenWeatherMap API Key
- `CITIES` ‚Äì St√§dte im Format: `Z√ºrich, CH;Bern, CH;Basel, CH`
- `TOPIC` ‚Äì Kafka Topic
- `PG_HOST`, `PG_DB`, `PG_USER`, `PG_PASSWORD`, `PG_PORT`

---

## üêç Lokales Testing (ohne Container)
Falls du das System ohne Docker testen m√∂chtest:
pip install -r requirements.txt

Dann in zwei Terminals ausf√ºhren:
python weather_producer.py  
python weather_beam.py

---
