# ğŸŒ¦ï¸ OpenWeatherMap Big Data Streaming Projekt

## ğŸ¯ Zielsetzung
Ziel dieses Projekts ist es, eine skalierbare, containerisierte Streaming-Pipeline zur Analyse und Visualisierung von Wetterdaten in Echtzeit aufzubauen. Dabei stehen Robustheit, Erweiterbarkeit (z.â€¯B. Anomalieerkennung) sowie Transparenz der Verarbeitung (z.â€¯B. durch Zeitstempel & Lag-Analyse) im Fokus.

---

## ğŸ—‚ï¸ ProjektÃ¼bersicht
Dieses Projekt streamt Wetterdaten von OpenWeatherMap in Echtzeit und verarbeitet sie Ã¼ber eine Event-Streaming-Pipeline. Die Daten werden in einer PostgreSQL-Datenbank gespeichert und mit Grafana visualisiert.

<pre><code>```text
OPENWEATHERMAP-BIGDATA-PROJECT/
â”œâ”€â”€ ai_model/
â”‚   â”œâ”€â”€ data/                            # Trainingsdaten fÃ¼r das ML-Modell
â”‚   â”‚   â”œâ”€â”€ 2022_05_01.xlsx
â”‚   â”‚   â”œâ”€â”€ 2022_05_02.xlsx
â”‚   â”‚   â”œâ”€â”€ 2022_05_03.xlsx
â”‚   â”‚   â””â”€â”€ anomalie.xlsx               # Validierungsset mit Labels
â”‚   â”œâ”€â”€ model/                          # Serialisiertes Modell und Scaler
â”‚   â”‚   â”œâ”€â”€ isolation_forest_model.pkl
â”‚   â”‚   â””â”€â”€ scaler.pkl
â”‚   â”œâ”€â”€ 01_training.ipynb               # Notebook zum Training (inkl. Export)
â”‚   â””â”€â”€ 02_predict_anomalies.ipynb      # Notebook zur Validierung & Analyse
â”œâ”€â”€ weather_producer.py                 # Producer: API-Aufrufe & Kafka-Push
â”œâ”€â”€ weather_beam.py                     # Beam-Consumer mit Preprocessing + ML
â”œâ”€â”€ Dockerfile-producer                 # Container-Konfiguration Producer
â”œâ”€â”€ Dockerfile-beam                     # Container-Konfiguration Beam + ML
â”œâ”€â”€ docker-compose.yml                  # Orchestriert alle Services
â”œâ”€â”€ grafana_json_export.json            # Importierbares Dashboard
â”œâ”€â”€ .env                                # Lokale Umgebungsvariablen (nicht committet)
â”œâ”€â”€ .env.example                        # Beispielhafte .env-Datei
â”œâ”€â”€ .gitignore                          # Ignoriert sensible / temporÃ¤re Dateien
â”œâ”€â”€ requirements.txt                    # Python-AbhÃ¤ngigkeiten
â””â”€â”€ readme.md                           # Projektdokumentation (dieses File)
```</code></pre>

---

**Architektur:**  
OpenWeatherMap â†’ Kafka â†’ Apache Beam â†’ PostgreSQL â†’ Grafana

Alle Komponenten laufen containerisiert Ã¼ber Docker Compose.

---

## ğŸ”§ Komponenten
| Komponente                        | Aufgabe                                       																			|
|----------------------------------|----------------------------------------------------------------------------------------------------------------------------|
| Kafka & Zookeeper                | Event-Streaming                               																				|
| PostgreSQL                       | Speicherung der Wetterdaten                   																				|
| Grafana                          | Visualisierung                                																				|
| weather_producer.py (Container)  | Holt Wetterdaten, ergÃ¤nzt event_time & received_time und sendet an Kafka       											|
| weather_beam.py (Container)      | Liest von Kafka, ergÃ¤nzt processing_time, filtert, erkennt Anomalien und speichert in PostgreSQL (inkl. Idempotenz)     	|


---

## ğŸ“‹ Gespeicherte Wetterdaten (weather_data)
| Feld             | Einheit / Typ        | Beschreibung                         					|
|------------------|----------------------|---------------------------------------------------------|
| city             | Text                 | Stadtname                            					|
| temperature      | Â°C                   | Temperatur                           					|
| humidity         | %                    | Luftfeuchtigkeit                     					|
| pressure         | hPa                  | Luftdruck                            					|
| wind_speed       | km/h                 | Windgeschwindigkeit (berechnet)      					|
| cloud_coverage   | %                    | BewÃ¶lkungsgrad                       					|
| weather_main     | Text                 | Wetterkategorie                      					|
| weather_description | Text              | Beschreibung                         					|
| timestamp        | Unix Time (s)        | Zeitpunkt der Messung                					|
| lon / lat        | Koordinaten          | Geografische Lage                    					|
| sys_country      | LÃ¤ndercode           | Nur CH wird gespeichert             					|
| event_time       | Unix Time (s)        | Zeitpunkt der Wettermessung (von API)           		|
| received_time    | Unix Time (s)        | Zeitpunkt, wann die Nachricht im Producer ankam 		|
| processing_time  | Unix Time (s)        | Zeitpunkt, wann der Datensatz in Beam verarbeitet wurde |

---

## ğŸ§ª Verarbeitungsschritte in der Apache Beam Pipeline
| Schritt                          | Beam-Typ         | Beschreibung                                                                 											|
|----------------------------------|------------------|-------------------------------------------------------------------------------------------------------------------------|
| Batch laden                      | beam.Create      | LÃ¤dt 10 gesammelte Kafka-Nachrichten in die Pipeline                         											|
| Debug falsche sys_country        | beam.Map         | Gibt EintrÃ¤ge mit sys_country â‰  'CH' zur Kontrolle aus                       											|
| Filtere nur sys_country = CH     | beam.Filter      | LÃ¤sst nur DatensÃ¤tze mit sys_country = 'CH' durch                            											|
| Debug ungÃ¼ltige Werte            | beam.Map         | Gibt DatensÃ¤tze mit fehlenden numerischen Werten (None) aus                  											|
| Filtere nur gÃ¼ltige Werte        | beam.Filter      | Filtert nur DatensÃ¤tze mit vollstÃ¤ndigen Werten (temperature, pressure, etc.)											|
| Windgeschwindigkeit umrechnen    | beam.Map         | Rechnet wind_speed von m/s in **km/h** um (Feldname bleibt gleich)           											|
| Processing-Zeit ergÃ¤nzen		   | beam.Map		  | FÃ¼gt processing_time als Unix-Zeit hinzu									 											|
| Anomalie erkennen                | beam.Map         | Erkennt Anomalien mit einem ML-Modell (Isolation Forest, via sklearn + pandas)              							|
| In PostgreSQL schreiben          | beam.Map         | Speichert die bereinigten DatensÃ¤tze in der PostgreSQL-Tabelle weather_data (mit Idempotenz (UNIQUE(city, timestamp))) 	|

---

## ğŸ§° Erweiterungen (Idempotenz, Zeitstempel, Retention, Anomalieerkennung mit Machine Learning)
**Zeitstempel:** Jeder Datensatz enthÃ¤lt drei Zeitpunkte fÃ¼r vollstÃ¤ndige Nachvollziehbarkeit:
- `event_time`: Zeitpunkt der Messung laut OpenWeatherMap
- `received_time`: Zeitpunkt, wann der Producer die Daten empfangen hat
- `processing_time`: Zeitpunkt, wann Apache Beam den Datensatz verarbeitet hat

**Idempotenz:**  
Duplikate werden vermieden durch `UNIQUE(city, timestamp)` in PostgreSQL + `ON CONFLICT DO NOTHING`.

**Retention:**  
Kafka ist auf eine standardmÃ¤ssige Aufbewahrung von 7 Tagen konfiguriert (`KAFKA_LOG_RETENTION_HOURS = 168`).

**VerzÃ¶gerungsanalyse (Lag):**  
Durch Vergleich von `processing_time` und `event_time` kann die Systemlatenz berechnet und visualisiert werden.

**Windowing & Triggering**  
In Apache Beam sind Zeitfenster und Trigger entscheidend fÃ¼r kontinuierliche Streamingverarbeitung. Da in diesem Projekt jedoch feste 10er-Batches verarbeitet werden, erfolgt keine explizite Zeitfensterung (`WindowInto`) oder Trigger-Logik. Die Batchebene Ã¼bernimmt implizit die Fensterlogik. Daher wird auch kein Watermark oder `AccumulationMode` benÃ¶tigt. Die Verarbeitung erfolgt mit dem Modus â€discardingâ€œ durch das explizite Ãœberschreiben der Datenbank.
â†’ Vorteil: einfache Kontrolle, deterministisches Verhalten und keine verzÃ¶gerten Nachlieferungen.

**Anomalieerkennung mit Machine Learningg**  
Der Unterordner ai_model/model/ enthÃ¤lt das produktive Machine-Learning-Modell (isolation_forest_model.pkl) und den zugehÃ¶rigen StandardScaler (scaler.pkl) zur Anomalieerkennung. Das Notebook 01_training.ipynb dokumentiert den gesamten Trainingsprozess und erlaubt ein spÃ¤teres Nachtraining oder Fine-Tuning des Modells mit aktualisierten Daten.

Enthaltene Dateien:
- 2022_05_01.xlsx, 2022_05_02.xlsx, 2022_05_03.xlsx: Rohdaten fÃ¼r das Training (wurden im Rahmen einer anderen Weiterbildung von Philippe Christen erhoben)
- anomalie.xlsx: validierte Anomalien zur Modell-Evaluierung (stark vereinfacht)
- training.ipynb: Jupyter Notebook zum Training inkl. Feature-Engineering & Modellpersistenz

Ziel: Reproduzierbarkeit und einfache Anpassung bei Modell-Drift oder verÃ¤nderten Datenmustern.

---

## ğŸ”‘ Konfiguration (.env)
Im Repository befindet sich die Datei `.env.example`.
Bitte kopiere diese und benenne sie in `.env` um.
Anschliessend trÃ¤gst du deinen persÃ¶nlichen API_KEY ein (wird im Rahmen des Projekts per E-Mail bereitgestellt)

---

## â–¶ï¸ Starten
Docker Desktop starten

**Build & Start der gesamten Umgebung:**
docker-compose build --no-cache  
docker-compose up -d

**Logs prÃ¼fen (optional):**
docker logs openweathermap-bigdata-project-producer-1  
docker logs openweathermap-bigdata-project-beam-1

**Kafka Live-Stream prÃ¼fen (optional --> Consumer wird in temporÃ¤ren Container gestartet):**
docker run -it --network=openweathermap-bigdata-project_default confluentinc/cp-kafka:7.5.0 \
kafka-console-consumer --bootstrap-server kafka:9092 --topic weather_data --from-beginning

**psql Abfrage (optional):**
docker exec -it openweathermap-bigdata-project-postgres-1 psql -U user -d weather
    SELECT * FROM weather_data ORDER BY timestamp DESC LIMIT 100;

**Stoppen:**
docker-compose down --remove-orphans

---

## ğŸ”‘ Zugangsdaten & Ports

| Dienst     | Adresse/Port          | Zugangsdaten   |
|------------|-----------------------|----------------|
| Kafka      | localhost:9092        | -              |
| PostgreSQL | localhost:5432        | user / pass    |
| Grafana    | http://localhost:3000 | admin / admin  |

---

## ğŸ“Š Grafana einrichten

### Datenquelle hinzufÃ¼gen
1. Links: âš™ Data Sources â†’ PostgreSQL auswÃ¤hlen.
2. Host: postgres:5432
3. Database: weather
4. User: user, Passwort: pass
5. Save & Test â†’ sollte â€Database OKâ€œ anzeigen.

### Panel erstellen â€” Beispiel-Querys

**Temperatur Ã¼ber Zeit:**
SELECT timestamp * 1000 AS "time", temperature  
FROM weather_data  
ORDER BY timestamp ASC;

**Luftfeuchtigkeit Ã¼ber Zeit:**
SELECT timestamp * 1000 AS "time", humidity  
FROM weather_data  
ORDER BY timestamp ASC;

**Lag-Analyse:**
SELECT (processing_time - event_time) AS lag_seconds 
FROM weather_data;

**Anomaly-Analyse:**
SELECT
  to_timestamp(processing_time) AS time,
  city, temperature, wind_speed, pressure, humidity
FROM
  weather_data
WHERE
  anomaly = true
ORDER BY
  processing_time DESC;

**Anomaly-Analyse Heatmap:**
SELECT city, COUNT(*) AS anomaly_count
FROM weather_data
WHERE anomaly = true
GROUP BY city
ORDER BY anomaly_count DESC;


**Importiertes Dashboard**
Das vorkonfigurierte Grafana-Dashboard ist als Datei grafana_json_export.json im Projekt enthalten.
Du kannst es wie folgt importieren:
	1.	Ã–ffne Grafana unter http://localhost:3000
	2.	Klicke auf â€+â€œ â†’ â€Importâ€œ
	3.	Lade die Datei grafana_json_export.json hoch oder fÃ¼ge den JSON-Inhalt ein
	4.	WÃ¤hle die PostgreSQL-Datenquelle aus und bestÃ¤tige mit Import


---

## âš™ï¸ .env-Konfiguration
Alle Parameter werden Ã¼ber die .env-Datei gesteuert:

**Beispielhafte Parameter:**
- `API_KEY` â€“ OpenWeatherMap API Key
- `CITIES` â€“ StÃ¤dte im Format: `ZÃ¼rich, CH;Bern, CH;Basel, CH`
- `TOPIC` â€“ Kafka Topic
- `PG_HOST`, `PG_DB`, `PG_USER`, `PG_PASSWORD`, `PG_PORT`

---

## ğŸ Lokales Testing (ohne Container)
Falls du das System ohne Docker testen mÃ¶chtest:
pip install -r requirements.txt

Dann in zwei Terminals ausfÃ¼hren:
python weather_producer.py  
python weather_beam.py

---
